{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xEHqvqLmk-AH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel,AutoTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import json\n",
        "import re\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from typing import List, Tuple\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process Pile-NER dataset**"
      ],
      "metadata": {
        "id": "SZ4d42u6PXXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#taken from GLiNER source code: https://github.com/urchade/GLiNER/blob/main/data/process_pilener.py\n",
        "\n",
        "def load_data(filepath):\n",
        "    \"\"\"Loads data from a JSON file.\"\"\"\n",
        "    with open(filepath, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def tokenize_text(text):\n",
        "    \"\"\"Tokenizes the input text into a list of tokens.\"\"\"\n",
        "    return re.findall(r'\\w+(?:[-_]\\w+)*|\\S', text)\n",
        "\n",
        "def extract_entity_spans(entry):\n",
        "    \"\"\"Extracts entity spans from an entry.\"\"\"\n",
        "    len_start = len(\"What describes \")\n",
        "    len_end = len(\" in the text?\")\n",
        "    entity_types, entity_texts, negative = [], [], []\n",
        "\n",
        "    for c in entry['conversations']:\n",
        "        if c['from'] == 'human' and c['value'].startswith('Text: '):\n",
        "            text = c['value'][len('Text: '):]\n",
        "            tokenized_text = tokenize_text(text)\n",
        "        elif c['from'] == 'human' and c['value'].startswith('What describes '):\n",
        "            entity_type = c['value'][len_start:-len_end]\n",
        "            entity_types.append(entity_type)\n",
        "        elif c['from'] == 'gpt' and c['value'].startswith('['):\n",
        "            if c['value'] == '[]':\n",
        "                negative.append(entity_types.pop())\n",
        "                continue\n",
        "            texts_ents = ast.literal_eval(c['value'])\n",
        "            entity_texts.extend(texts_ents)\n",
        "            num_repeat = len(texts_ents) - 1\n",
        "            entity_types.extend([entity_types[-1]] * num_repeat)\n",
        "\n",
        "    entity_spans = []\n",
        "    for j, entity_text in enumerate(entity_texts):\n",
        "        entity_tokens = tokenize_text(entity_text)\n",
        "        matches = []\n",
        "        for i in range(len(tokenized_text) - len(entity_tokens) + 1):\n",
        "            if \" \".join(tokenized_text[i:i + len(entity_tokens)]).lower() == \" \".join(entity_tokens).lower():\n",
        "                matches.append((i, i + len(entity_tokens) - 1, entity_types[j]))\n",
        "        if matches:\n",
        "            entity_spans.extend(matches)\n",
        "\n",
        "    return {\"tokenized_text\": tokenized_text, \"ner\": entity_spans, \"negative\": negative}\n",
        "\n",
        "def process_data(data):\n",
        "    \"\"\"Processes a list of data entries to extract entity spans.\"\"\"\n",
        "    all_data = [extract_entity_spans(entry) for entry in tqdm(data)]\n",
        "    return all_data\n",
        "\n",
        "def save_data_to_file(data, filepath):\n",
        "    \"\"\"Saves the processed data to a JSON file.\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(data, f)"
      ],
      "metadata": {
        "id": "U-XYY5xtlDle"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process CrossNER datasets**"
      ],
      "metadata": {
        "id": "m7C3h_OWPe-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#taken from https://github.com/zliucr/CrossNER/tree/main/src\n",
        "def process_conll_data(file_path):\n",
        "    \"\"\"\n",
        "    Processes a CONLL-format file into the processed_data format with dynamic entity type extraction.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the CONLL-format file.\n",
        "\n",
        "    Returns:\n",
        "        List of processed examples in the desired format.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    sentence_tokens = []\n",
        "    sentence_labels = []\n",
        "    all_entity_types = set()\n",
        "\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if sentence_tokens:\n",
        "                    ner_entities = []\n",
        "                    for idx, label in enumerate(sentence_labels):\n",
        "                        if label != \"O\":\n",
        "                            entity_type = label[2:]\n",
        "                            all_entity_types.add(entity_type)\n",
        "                            if label.startswith(\"B-\"):\n",
        "                                ner_entities.append((idx, idx, entity_type))\n",
        "                            elif label.startswith(\"I-\") and ner_entities:\n",
        "                                ner_entities[-1] = (\n",
        "                                    ner_entities[-1][0],\n",
        "                                    idx,\n",
        "                                    ner_entities[-1][2],\n",
        "                                )\n",
        "\n",
        "                    sentence_entity_types = {ent[2] for ent in ner_entities}\n",
        "\n",
        "                    negative_types = list(all_entity_types - sentence_entity_types)\n",
        "\n",
        "                    data.append({\n",
        "                        \"tokenized_text\": sentence_tokens,\n",
        "                        \"ner\": ner_entities,\n",
        "                        \"negative\": negative_types,\n",
        "                    })\n",
        "\n",
        "                sentence_tokens = []\n",
        "                sentence_labels = []\n",
        "            else:\n",
        "                token, label = line.split()\n",
        "                sentence_tokens.append(token)\n",
        "                sentence_labels.append(label)\n",
        "\n",
        "    for example in data:\n",
        "        example[\"negative\"] = list(all_entity_types - {ent[2] for ent in example[\"ner\"]})\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "lzsU9lp0KWiQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GLiNER Model**"
      ],
      "metadata": {
        "id": "DzT99ErtPkTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GLiNER(nn.Module):\n",
        "    def __init__(self, pretrained_model_name, tokenizer, max_span_length=12, hidden_size=768):\n",
        "        super(GLiNER, self).__init__()\n",
        "\n",
        "        #tokenizer\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        #encoder\n",
        "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        self.encoder.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "        #hyperparams\n",
        "        self.hidden_size = hidden_size\n",
        "        self.max_span_length = max_span_length\n",
        "\n",
        "        #FFN for span rep\n",
        "        self.span_ffn = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size * 2, self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_size, self.hidden_size),\n",
        "        )\n",
        "        #FFN for entity rep\n",
        "        self.entity_ffn = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size, self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_size, self.hidden_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        # encoder layer\n",
        "        encoder_output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        token_embeddings = encoder_output.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        # entity embeddings\n",
        "        ent_token_id = self.tokenizer.convert_tokens_to_ids(\"[ENT]\")\n",
        "        ent_positions = (input_ids == ent_token_id).nonzero(as_tuple=True)\n",
        "        entity_embeddings = token_embeddings[ent_positions[0], ent_positions[1], :]  # (num_entities, hidden_size)\n",
        "        refined_entity_embeddings = self.entity_ffn(entity_embeddings)\n",
        "\n",
        "        # span embeddings\n",
        "        spans, span_embeddings = self.create_span_embeddings(token_embeddings, attention_mask, input_ids)\n",
        "\n",
        "        # span-entity matching\n",
        "        span_scores = self.compute_span_scores(span_embeddings, refined_entity_embeddings)\n",
        "\n",
        "        return spans, span_scores\n",
        "\n",
        "    def create_span_embeddings(self, token_embeddings, attention_mask, input_ids):\n",
        "\n",
        "        batch_size, seq_len, _ = token_embeddings.size()\n",
        "        spans = []\n",
        "        span_embeddings = []\n",
        "\n",
        "        special_token_ids = [self.tokenizer.convert_tokens_to_ids(\"[ENT]\"), self.tokenizer.sep_token_id]\n",
        "\n",
        "        #ignore special tokens for embeddings\n",
        "        for batch_idx in range(batch_size):\n",
        "            for start in range(seq_len):\n",
        "                for end in range(start, min(start + self.max_span_length, seq_len)):\n",
        "                    if (\n",
        "                        attention_mask[batch_idx, start] == 0\n",
        "                        or attention_mask[batch_idx, end] == 0\n",
        "                        or input_ids[batch_idx, start] in special_token_ids\n",
        "                        or input_ids[batch_idx, end] in special_token_ids\n",
        "                    ):\n",
        "                        continue\n",
        "\n",
        "                    # generate span embeddings\n",
        "                    spans.append((batch_idx, start, end))\n",
        "                    start_embedding = token_embeddings[batch_idx, start, :]\n",
        "                    end_embedding = token_embeddings[batch_idx, end, :]\n",
        "                    span_embedding = torch.cat((start_embedding, end_embedding), dim=-1)\n",
        "                    span_embeddings.append(self.span_ffn(span_embedding))\n",
        "\n",
        "        span_embeddings = torch.stack(span_embeddings) if span_embeddings else torch.empty(0, self.hidden_size)\n",
        "        return spans, span_embeddings\n",
        "\n",
        "    def compute_span_scores(self, span_embeddings, entity_embeddings):\n",
        "\n",
        "        # dot product\n",
        "        scores = torch.matmul(span_embeddings, entity_embeddings.T)\n",
        "\n",
        "        # apply sigmoid to normalize between 0-1\n",
        "        span_scores = torch.sigmoid(scores)\n",
        "\n",
        "        return span_scores\n",
        "\n"
      ],
      "metadata": {
        "id": "_8DeSC5et8m5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GLiNER Dataset class**"
      ],
      "metadata": {
        "id": "-arU33jlPnw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collate data function**"
      ],
      "metadata": {
        "id": "SHkPnNRkPvMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_func(batch):\n",
        "\n",
        "    # pad input_ids and attention_mask to the same length\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "        [item[\"input_ids\"] for item in batch], batch_first=True, padding_value=0\n",
        "    )\n",
        "    attention_mask = torch.nn.utils.rnn.pad_sequence(\n",
        "        [item[\"attention_mask\"] for item in batch], batch_first=True, padding_value=0\n",
        "    )\n",
        "\n",
        "    spans = [item[\"spans\"] for item in batch]\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"spans\": spans,\n",
        "        \"labels\": labels,\n",
        "    }"
      ],
      "metadata": {
        "id": "03Uo-5lK17YY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlinerDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_seq_length=512, max_span_length=12,max_entity_types=25):\n",
        "\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.max_span_length = max_span_length\n",
        "        self.max_entity_types = max_entity_types\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        item = self.data[idx]\n",
        "\n",
        "        #limit to 25 entities per sentence\n",
        "        all_entity_types = list(set([ent[2] for ent in item[\"ner\"]] + item[\"negative\"]))\n",
        "        if len(all_entity_types) > self.max_entity_types:\n",
        "            all_entity_types = random.sample(all_entity_types, self.max_entity_types)\n",
        "\n",
        "        # format input\n",
        "        entity_type_str = \" \".join([f\"[ENT] {etype}\" for etype in all_entity_types])\n",
        "\n",
        "        text = \" \".join(item[\"tokenized_text\"])\n",
        "        formatted_input = f\"{entity_type_str} [SEP] {text}\"\n",
        "\n",
        "        # tokenize\n",
        "        tokenized = self.tokenizer(\n",
        "            formatted_input, padding=\"max_length\", truncation=True, max_length=self.max_seq_length, return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids = tokenized[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = tokenized[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        # generate spans\n",
        "        positive_spans = item[\"ner\"]\n",
        "        positive_labels = {(start, end): 1 for start, end, _ in positive_spans}\n",
        "        spans = []\n",
        "        labels = []\n",
        "\n",
        "        #ignore special tokens for spans and labels\n",
        "        special_token_ids = [self.tokenizer.convert_tokens_to_ids(\"[ENT]\"), self.tokenizer.sep_token_id]\n",
        "        for start in range(len(input_ids)):\n",
        "            for end in range(start, min(start + self.max_span_length, len(input_ids))):\n",
        "                if (\n",
        "                    input_ids[start].item() in special_token_ids\n",
        "                    or input_ids[end].item() in special_token_ids\n",
        "                    or attention_mask[start].item() == 0\n",
        "                    or attention_mask[end].item() == 0\n",
        "                ):\n",
        "                    continue\n",
        "                spans.append((start, end))\n",
        "                labels.append(positive_labels.get((start, end), 0))\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"spans\": spans,\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.float),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "yBDIycPAuId0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Function**"
      ],
      "metadata": {
        "id": "-4QYXBs2Prz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gliner_model(model, dataloader, optimizer, num_epochs, device, threshold=0.5):\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss, total_correct, total_spans = 0.0, 0, 0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            spans = batch[\"spans\"]\n",
        "            labels = [label.to(device) for label in batch[\"labels\"]]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            _, span_scores = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            loss = 0.0\n",
        "            score_idx = 0\n",
        "\n",
        "            for item_idx, (item_spans, item_labels) in enumerate(zip(spans, labels)):\n",
        "                # get score for item\n",
        "                item_scores = span_scores[score_idx:score_idx + len(item_spans)]\n",
        "\n",
        "                # skip if no valid spans\n",
        "                if item_scores.size(0) == 0:\n",
        "                    continue\n",
        "\n",
        "                item_labels = item_labels.to(device)\n",
        "\n",
        "                # expand labels to match num entity types\n",
        "                if item_labels.dim() == 1:\n",
        "                    expanded_labels = torch.zeros(\n",
        "                        item_labels.size(0), item_scores.size(1), device=device\n",
        "                    )\n",
        "                    expanded_labels.scatter_(1, item_labels.long().unsqueeze(1), 1)\n",
        "                    item_labels = expanded_labels\n",
        "\n",
        "                # compute binary cross-entropy for this item\n",
        "                loss += F.binary_cross_entropy(item_scores, item_labels)\n",
        "\n",
        "                # predictions for accuracy\n",
        "                predictions = (item_scores > threshold).long()\n",
        "                total_correct += (predictions == item_labels).sum().item()\n",
        "                total_spans += len(item_labels)\n",
        "\n",
        "                # next\n",
        "                score_idx += len(item_spans)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        accuracy = total_correct / total_spans if total_spans > 0 else 0\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TUe8SVzauOOg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize and Train**"
      ],
      "metadata": {
        "id": "0q1G1jhpQl7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#path_pile_ner = 'train.json'\n",
        "#data = load_data(path_pile_ner)\n",
        "#processed_data = process_data(data)\n",
        "#save_data_to_file(processed_data, 'pilener_train.json')\n",
        "processed_data = load_data('pilener_train.json')\n",
        "print(\"dataset size:\", len(processed_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf1WNEcKlFrF",
        "outputId": "3f4bdaf2-d6ea-4483-df43-34b2d8765574"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: 45889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#load tokenizer and add special tokens\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "special_tokens = {\"additional_special_tokens\": [\"[ENT]\", \"[SEP]\"]}\n",
        "tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "# initialize model\n",
        "model = GLiNER(pretrained_model_name=\"microsoft/deberta-v3-small\", tokenizer=tokenizer, max_span_length=12)\n",
        "\n",
        "#resize embeddings to accomodate new tokens\n",
        "model.encoder.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcjagzZLxC2b",
        "outputId": "8b756368-2c16-4640-a0ae-8c2990f6f5c3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(128002, 768, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just trying a subset of data...\n",
        "data = processed_data[:200]\n",
        "\n",
        "#prepare dataset and dataloader with custom collate function\n",
        "dataset = GlinerDataset(data, tokenizer, max_span_length=12)"
      ],
      "metadata": {
        "id": "wB0yh-GCzuRW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_func,)\n",
        "\n",
        "#optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "#epochs\n",
        "num_epochs = 3\n",
        "\n",
        "#total steps\n",
        "total_steps = len(dataloader) * num_epochs"
      ],
      "metadata": {
        "id": "-vLu_pHU10n1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train_gliner_model(model, dataloader, optimizer, num_epochs=num_epochs, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmoHyG6Zz8ot",
        "outputId": "ac6fe62a-f70f-4440-8072-d635e9ed31b4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 15.5279, Accuracy: 53.8741\n",
            "Epoch 2, Loss: 13.2279, Accuracy: 53.6064\n",
            "Epoch 3, Loss: 13.9754, Accuracy: 54.1247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Greedy Decoding algorithm (Flat NER)**"
      ],
      "metadata": {
        "id": "IHlBnNGXQXOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Flat NER Greedy Decoding algorithm\n",
        "def greedy_decode(spans, span_scores, threshold=0.1):\n",
        "\n",
        "    scored_spans = [(span, score.item()) for span, score in zip(spans, span_scores) if score > threshold]\n",
        "    scored_spans = sorted(scored_spans, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    selected_spans = []\n",
        "    for span, score in scored_spans:\n",
        "        if all(span[1] < other[0] or span[0] > other[1] for other, _ in selected_spans):\n",
        "            selected_spans.append((span, score))\n",
        "\n",
        "    return selected_spans"
      ],
      "metadata": {
        "id": "6sQPFinEg_IY"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Function**"
      ],
      "metadata": {
        "id": "uLzH4UL5Qa0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_gliner_model(model, dataloader, device, threshold=0.1):\n",
        "    \"\"\"\n",
        "    Evaluate the GLiNER model on a validation/test dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The trained GLiNER model.\n",
        "        dataloader: DataLoader providing the evaluation data.\n",
        "        device: Device to run the evaluation on (e.g., \"cuda\" or \"cpu\").\n",
        "        threshold: Classification threshold for span predictions.\n",
        "\n",
        "    Returns:\n",
        "        metrics: A dictionary containing precision, recall, and F1-score.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_true_spans = []\n",
        "    all_predicted_spans = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            spans = batch[\"spans\"]\n",
        "            labels = [label.cpu().numpy() for label in batch[\"labels\"]]\n",
        "\n",
        "            predicted_spans, span_scores = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            decoded_spans = greedy_decode(predicted_spans, span_scores.flatten(), threshold)\n",
        "\n",
        "            for item_spans, item_labels, item_decoded in zip(spans, labels, decoded_spans):\n",
        "                true_spans = [span for span, label in zip(item_spans, item_labels) if label == 1]\n",
        "                all_true_spans.append(true_spans)\n",
        "\n",
        "                predicted_spans = [span for span, _ in item_decoded]\n",
        "                all_predicted_spans.append(predicted_spans)\n",
        "\n",
        "    flat_true = [span for spans in all_true_spans for span in spans]\n",
        "    flat_pred = [span for spans in all_predicted_spans for span in spans]\n",
        "\n",
        "    precision = precision_score(flat_true, flat_pred, average=\"micro\", zero_division=0)\n",
        "    recall = recall_score(flat_true, flat_pred, average=\"micro\", zero_division=0)\n",
        "    f1 = f1_score(flat_true, flat_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    metrics = {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1\n",
        "    }\n",
        "\n",
        "    print(f\"Evaluation Metrics: Precision={precision:.4f}, Recall={recall:.4f}, F1-Score={f1:.4f}\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "l8-Tprn3JyKf"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate**"
      ],
      "metadata": {
        "id": "eXbfET0OQiZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crossner_ai_test = process_conll_data(\"test.txt\")"
      ],
      "metadata": {
        "id": "lAPgu3V2Kirn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = crossner_ai_test[:20]\n",
        "validation_dataset = GlinerDataset(validation_data, tokenizer, max_span_length=12)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_dataset, batch_size=8, shuffle=False, collate_fn=collate_func\n",
        ")"
      ],
      "metadata": {
        "id": "VJ6XCBZQLCcd"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate_gliner_model(trained_model, validation_dataloader, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO0o3dGLNrJS",
        "outputId": "5f07bbd2-320b-4914-ec80-cd6a1346e2bb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics: Precision=0.0000, Recall=0.0000, F1-Score=0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVNJVIqrdNHY",
        "outputId": "05fa490e-9768-4e4e-9162-12080d762b2c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYhnTiK9dOCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}